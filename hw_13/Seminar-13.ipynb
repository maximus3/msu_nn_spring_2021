{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.14"},"colab":{"name":"Seminar-13.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"Miw-5y_wPdCF"},"source":["## Семинар 13: \"Обучение с подкреплением 1\""]},{"cell_type":"markdown","metadata":{"id":"mxGpPFaiPdCS"},"source":["ФИО: Иванов Максим Юрьевич\n"]},{"cell_type":"markdown","metadata":{"id":"USPO01wDPdCW"},"source":["###  FrozenLake\n","\n","\n","<img src=\"http://vignette2.wikia.nocookie.net/riseoftheguardians/images/4/4c/Jack's_little_sister_on_the_ice.jpg/revision/latest?cb=20141218030206\" alt=\"a random image to attract attention\" style=\"width: 400px;\"/>\n","\n"]},{"cell_type":"code","metadata":{"id":"_L_9LujNPdCc"},"source":["import gym\n","import numpy as np \n","\n","#create a single game instance\n","env = gym.make(\"FrozenLake-v0\")\n","\n","#start new game\n","env.reset();"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-CdtVt2sPdCn","executionInfo":{"status":"ok","timestamp":1621589402345,"user_tz":-180,"elapsed":15,"user":{"displayName":"Максим Иванов","photoUrl":"","userId":"13928116544814490129"}},"outputId":"44554098-d244-41a7-8a93-e15ccfe6fa44"},"source":["# display the game state\n","env.render()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","\u001b[41mS\u001b[0mFFF\n","FHFH\n","FFFH\n","HFFG\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TQ7nTooRPdCr"},"source":["### legend\n","\n","![img](https://cdn-images-1.medium.com/max/800/1*MCjDzR-wfMMkS0rPqXSmKw.png)"]},{"cell_type":"markdown","metadata":{"id":"WViC3bdvPdCu"},"source":["### Gym interface\n","\n","The three main methods of an environment are\n","* __reset()__ - reset environment to initial state, _return first observation_\n","* __render()__ - show current environment state (a more colorful version :) )\n","* __step(a)__ - commit action __a__ and return (new observation, reward, is done, info)\n"," * _new observation_ - an observation right after commiting the action __a__\n"," * _reward_ - a number representing your reward for commiting action __a__\n"," * _is done_ - True if the MDP has just finished, False if still in progress\n"," * _info_ - some auxilary stuff about what just happened. Ignore it for now"]},{"cell_type":"code","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"jfd2Q67ZPdCy","executionInfo":{"status":"ok","timestamp":1621589546209,"user_tz":-180,"elapsed":256,"user":{"displayName":"Максим Иванов","photoUrl":"","userId":"13928116544814490129"}},"outputId":"b9b8227f-3cbc-48d7-c532-6da728a269b1"},"source":["print(\"initial observation code:\", env.reset())\n","print('printing observation:')\n","env.render()\n","print(\"observations:\", env.observation_space, 'n=', env.observation_space.n)\n","print(\"actions:\", env.action_space, 'n=', env.action_space.n)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["('initial observation code:', 0)\n","printing observation:\n","\n","\u001b[41mS\u001b[0mFFF\n","FHFH\n","FFFH\n","HFFG\n","('observations:', Discrete(16), 'n=', 16)\n","('actions:', Discrete(4), 'n=', 4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SUq5qme1PdC4","executionInfo":{"status":"ok","timestamp":1621589558761,"user_tz":-180,"elapsed":249,"user":{"displayName":"Максим Иванов","photoUrl":"","userId":"13928116544814490129"}},"outputId":"09eb4f58-4a89-4413-e16e-a456d646211a"},"source":["print(\"taking action 2 (right)\")\n","new_obs, reward, is_done, _ = env.step(2)\n","print(\"new observation code:\", new_obs)\n","print(\"reward:\", reward)\n","print(\"is game over?:\", is_done)\n","print(\"printing new state:\")\n","env.render()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["taking action 2 (right)\n","('new observation code:', 4)\n","('reward:', 0.0)\n","('is game over?:', False)\n","printing new state:\n","  (Right)\n","SFFF\n","\u001b[41mF\u001b[0mHFH\n","FFFH\n","HFFG\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q3l8I2j1PdC8"},"source":["action_to_i = {\n","    'left':0,\n","    'down':1,\n","    'right':2,\n","    'up':3\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"His8abt_PdC-"},"source":["### Попробуйте походить по замерзшему озеру, не упав в дырку. \n","* Каждый шаг вы с вероятностью __0.5__ будете двигаться в выбранном направлении и с вероятностью __0.5__ в случайном.\n","* Если упадете, используйте __env.reset()__ чтобы перезапустить __env__"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KdgemMH8PdDB","executionInfo":{"status":"ok","timestamp":1621589792388,"user_tz":-180,"elapsed":902,"user":{"displayName":"Максим Иванов","photoUrl":"","userId":"13928116544814490129"}},"outputId":"6eacc6f3-4f21-401f-ba34-caa7ad494617"},"source":["env.reset()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cr3_8ijrPdDE","executionInfo":{"status":"ok","timestamp":1621589822343,"user_tz":-180,"elapsed":250,"user":{"displayName":"Максим Иванов","photoUrl":"","userId":"13928116544814490129"}},"outputId":"21c35d18-30d0-4970-d9f1-b4fd48f02e92"},"source":["env.step(action_to_i['right'])\n","env.render()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  (Right)\n","SFFF\n","FHFH\n","FFFH\n","HFF\u001b[41mG\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6eUmeYh2PdDJ"},"source":["## Задание: \n","Следуя шаблонам функций реализуйте алгоритм Policy iteration.\n","Протестируйте его с помощью функции __evaluate_policy__.\n","Попробуйте разные значение для gamma и сравните результаты."]},{"cell_type":"code","metadata":{"id":"-QO-1cBpPdDO"},"source":["def run_episode(env, policy, gamma=1.0, render=False):\n","    obs = env.reset()\n","    total_reward = 0\n","    step_idx = 0\n","    while True:\n","        if render:\n","            env.render()\n","        obs, reward, done , _ = env.step(int(policy[obs]))\n","        total_reward += (gamma ** step_idx * reward)\n","        step_idx += 1\n","        if done:\n","            break\n","    return total_reward"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zxSGswHVPdDR"},"source":["def evaluate_policy(env, policy, gamma=1.0,  n=100):\n","    scores = [\n","            run_episode(env, policy, gamma=gamma, render=False)\n","            for _ in range(n)]\n","    return np.mean(scores)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tlhvQdSrUUUr","executionInfo":{"status":"ok","timestamp":1621590511679,"user_tz":-180,"elapsed":247,"user":{"displayName":"Максим Иванов","photoUrl":"","userId":"13928116544814490129"}},"outputId":"b4dbacde-c0e0-426f-b26e-fbc2eb0030e6"},"source":["env.env.P[14]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: [(0.3333333333333333, 10, 0.0, False),\n","  (0.3333333333333333, 13, 0.0, False),\n","  (0.3333333333333333, 14, 0.0, False)],\n"," 1: [(0.3333333333333333, 13, 0.0, False),\n","  (0.3333333333333333, 14, 0.0, False),\n","  (0.3333333333333333, 15, 1.0, True)],\n"," 2: [(0.3333333333333333, 14, 0.0, False),\n","  (0.3333333333333333, 15, 1.0, True),\n","  (0.3333333333333333, 10, 0.0, False)],\n"," 3: [(0.3333333333333333, 15, 1.0, True),\n","  (0.3333333333333333, 10, 0.0, False),\n","  (0.3333333333333333, 13, 0.0, False)]}"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"id":"jIrJvVWEPdDU"},"source":["# Используя фиксированную value_function и жадную стратегию получите policy\n","\n","def extract_policy(v, gamma = 1.0):\n","    policy = np.zeros(env.env.nS)\n","    q = np.zeros((env.env.nS, env.action_space.n))\n","    for state in env.env.P.keys():\n","        for action in env.env.P[state].keys():\n","            for prob, new_state, reward, _ in env.env.P[state][action]:\n","                q[state, action] += prob * reward + prob * gamma * v[new_state]\n","        policy[state] = np.argmax(q[state, :])\n","    return policy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AJ9kSTmUPdDX"},"source":["# Используя фиксированную policy с помощью сэмплирования получите оценку для value_function с точностью 1e-10\n","\n","def compute_policy_v(env, policy, gamma=1.0):\n","    v = np.zeros(env.env.nS)\n","    v_prev = np.ones(env.env.nS)\n","    while np.linalg.norm(v - v_prev) > 1e-10:\n","        v_prev = v.copy()\n","        for state in env.env.P.keys():\n","            v[state] = np.sum([prob * (reward + gamma * v_prev[new_state]) \n","                               for prob, new_state, reward, _ in env.env.P[state][policy[state]]])\n","    return v"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L3lAklQBPdDa"},"source":["def policy_iteration(env, gamma=1.0):\n","    max_iterations = 100000\n","    policy = np.random.choice(np.arange(env.env.nA), env.env.nS)\n","    for i in range(max_iterations):\n","        old_policy_v = compute_policy_v(env, policy, gamma)\n","        new_policy = extract_policy(old_policy_v, gamma)\n","        if (np.all(policy == new_policy)):\n","            break\n","\n","        policy = new_policy\n","    return policy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s0HqY_woPdDc"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_1XfXZIaPdDd","executionInfo":{"status":"ok","timestamp":1621591054750,"user_tz":-180,"elapsed":1019,"user":{"displayName":"Максим Иванов","photoUrl":"","userId":"13928116544814490129"}},"outputId":"767fe2e2-728a-4032-da9b-33ac3e01bde8"},"source":["for gamma in np.linspace(0.01, 1, 10):\n","    env = gym.make(\"FrozenLake-v0\")\n","    optimal_policy = policy_iteration(env, gamma=gamma)\n","    policy_score = evaluate_policy(env, optimal_policy, gamma, n=100)\n","\n","    print(gamma, policy_score)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(0.01, 2.000001020102021e-18)\n","(0.12, 3.082947052900832e-08)\n","(0.23, 3.767846151938489e-07)\n","(0.34, 6.23631901707355e-05)\n","(0.45, 0.0001263003025203008)\n","(0.56, 0.0005809434610856999)\n","(0.67, 0.001966552462138066)\n","(0.78, 0.006675637703661324)\n","(0.89, 0.06313866775959939)\n","(1.0, 0.76)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"collapsed":true,"id":"oTOSrHmePdDf"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZnbXHeMdPdDg"},"source":[""],"execution_count":null,"outputs":[]}]}